{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import All modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing sys\n",
    "import sys\n",
    "\n",
    "# adding Folder_2 to the system path\n",
    "sys.path.insert(0, '/home/jeongeun/test_env/Open-Set-Object-Detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI2 THOR\n",
    "!pkill thor_*\n",
    "import ai2thor\n",
    "from ai2thor.controller import Controller,BFSController\n",
    "from ai2thor.platform import CloudRendering\n",
    "from ithor_tools.vis_tool import *\n",
    "from ithor_tools.transform import cornerpoint_projection,depth2world\n",
    "from ithor_tools.map2 import single_scenemap\n",
    "from ithor_tools.landmark_utils import gather,vis_panorama,Word_Dict,choose_ladmark\n",
    "import random\n",
    "import math\n",
    "# from IPython.display import display\n",
    "# from moviepy.editor import ImageSequenceClip,VideoFileClip\n",
    "\n",
    "# Co occurance module\n",
    "from co_occurance.comet_co import co_occurance_score\n",
    "from co_occurance.move import co_occurance_based_schedular\n",
    "\n",
    "# Planning Module\n",
    "from RRT import gridmaprrt as rrt\n",
    "from RRT import gridmaprrt_pathsmoothing as smoothing\n",
    "# from IPython.display import Image as IM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detector module\n",
    "from data.phase_1 import load_voc_instances,VOC_CLASS_NAMES\n",
    "import torch\n",
    "import cv2\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from structures.box import Boxes\n",
    "from engine.predictor import DefaultPredictor\n",
    "\n",
    "from  config.config import get_cfg\n",
    "from model.rcnn import GeneralizedRCNN\n",
    "from detector.postprocess import postprocess,plot_openset,plot_candidate\n",
    "\n",
    "## Matching Module\n",
    "from detector.query_matching import matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup AI2THOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSize=0.05\n",
    "scene_name = \"FloorPlan_Train8_1\"\n",
    "controller = Controller(\n",
    "    platform = CloudRendering,\n",
    "    agentMode=\"locobot\",\n",
    "    visibilityDistance=5.0,\n",
    "    scene = scene_name,\n",
    "    gridSize=gridSize,\n",
    "    movementGaussianSigma=0,\n",
    "    rotateStepDegrees=90,\n",
    "    rotateGaussianSigma=0,\n",
    "    renderClassImage = True,\n",
    "    renderDepthImage=False,\n",
    "    renderInstanceSegmentation=False,\n",
    "    width=300,\n",
    "    height=300,\n",
    "    fieldOfView=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.reset(\n",
    "    # makes the images a bit higher quality\n",
    "    width=800,\n",
    "    height=800,\n",
    "\n",
    "    # Renders several new image modalities\n",
    "    renderDepthImage=True,\n",
    "    renderClassImage = True,\n",
    "    renderSemanticSegmentation=False,\n",
    "    renderNormalsImage=False\n",
    ")\n",
    "scene_bounds = controller.last_event.metadata['sceneBounds']['center']\n",
    "controller.step(\n",
    "    action=\"AddThirdPartyCamera\",\n",
    "    position=dict(x=scene_bounds['x'], y=5.0, z=scene_bounds['z']),\n",
    "    rotation=dict(x=90, y=0, z=0),\n",
    "    orthographic=True,\n",
    "    orthographicSize= 5.0, fieldOfView=100,\n",
    "    skyboxColor=\"white\"\n",
    ")\n",
    "controller.step(dict(action='GetReachablePositions'))\n",
    "rstate = controller.last_event.metadata['actionReturn']\n",
    "\n",
    "controller.step(\n",
    "    action=\"Teleport\",\n",
    "    position = rstate[100]\n",
    ")\n",
    "\n",
    "pos = controller.last_event.metadata['agent']['position']\n",
    "pos = [pos['x'],pos['z']]\n",
    "objects = controller.last_event.metadata['objects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = show_objects_table(objects)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Object Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks,visible_landmark_name = choose_ladmark(objects)\n",
    "landmark_cat = [Word_Dict[l] for l in visible_landmark_name]\n",
    "# query_object = random.choice(objects)\n",
    "query_object = objects[15] #20\n",
    "query_object_name = query_object['objectType']\n",
    "\n",
    "print(query_object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Co occurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurance_scoring = co_occurance_score('cuda:1')\n",
    "co_occurance_scoring.landmark_init(landmark_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_bounds = controller.last_event.metadata['sceneBounds']['cornerPoints']\n",
    "scene_bounds = cornerpoint_projection(scene_bounds)\n",
    "\n",
    "sm = single_scenemap(scene_bounds,rstate,stepsize = 0.1,\n",
    "                landmark_names=visible_landmark_name,landmarks=landmarks)\n",
    "sm.plot_landmarks(controller,show=False)\n",
    "landmark_config = dict(name=visible_landmark_name,color = sm.landmark_colors)\n",
    "imshow_grid = sm.plot(controller.last_event.metadata['agent']['position'],query_object['position'])\n",
    "plot_frames(controller.last_event,imshow_grid,landmark_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "config file\n",
    "'''\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file('../Open-Set-Object-Detection/config_files/voc.yaml')\n",
    "cfg.MODEL.SAVE_IDX=19 #22\n",
    "cfg.MODEL.RPN.USE_MDN=False\n",
    "cfg.log = False \n",
    "cfg.MODEL.ROI_HEADS.USE_MLN = True\n",
    "cfg.MODEL.ROI_HEADS.AUTO_LABEL = False\n",
    "cfg.MODEL.ROI_HEADS.AF = 'baseline'\n",
    "cfg.MODEL.RPN.AUTO_LABEL = False\n",
    "cfg.MODEL.ROI_BOX_HEAD.USE_FD = False\n",
    "cfg.MODEL.RPN.AUTO_LABEL_TYPE = 'sum'\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 21\n",
    "cfg.INPUT.RANDOM_FLIP = \"none\"\n",
    "cfg.MODEL.ROI_HEADS.UNCT = True\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.2\n",
    "cfg.PATH = '../Open-Set-Object-Detection'\n",
    "\n",
    "# cfg.merge_from_list(args.opts)\n",
    "RPN_NAME = 'mdn' if cfg.MODEL.RPN.USE_MDN else 'base'\n",
    "ROI_NAME = 'mln' if cfg.MODEL.ROI_HEADS.USE_MLN else 'base'\n",
    "MODEL_NAME = RPN_NAME + ROI_NAME\n",
    "# cfg.merge_from_list(args.opts)\n",
    "cfg.freeze()\n",
    "# wandb.init(config=cfg,tags= 'temp',name = 'temp',project='temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'\n",
    "model = GeneralizedRCNN(cfg,device = device).to(device)\n",
    "state_dict = torch.load('../Open-Set-Object-Detection/ckpt/{}/{}_{}_15000.pt'.format(cfg.MODEL.ROI_HEADS.AF,cfg.MODEL.SAVE_IDX,MODEL_NAME),map_location=device)\n",
    "pretrained_dict = {k: v for k, v in state_dict.items() if k in model.state_dict()}\n",
    "model.load_state_dict(pretrained_dict)\n",
    "\n",
    "predictor = DefaultPredictor(cfg,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Example of Openset Detection\n",
    "'''\n",
    "VOC_CLASS_NAMES = (\n",
    "    \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\",\n",
    "    \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\",\n",
    "    \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\", 'unknown'\n",
    ")\n",
    "\n",
    "img = controller.last_event.cv2img\n",
    "pred = predictor(img)\n",
    "pred_boxes, pred_classes,_ = postprocess(pred)\n",
    "plot_openset(img,pred_boxes,pred_classes,VOC_CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load Matcher\n",
    "'''\n",
    "query_matcher = matcher(query_object_name,threshold=29,device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-occurance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 0.6\n",
    "res = co_occurance_scoring.score(query_object_name)\n",
    "print(res,visible_landmark_name)\n",
    "if max(res)<thres:\n",
    "    thres = max(res)-0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Move to inital position\n",
    "'''\n",
    "controller.step(\n",
    "    action=\"Teleport\",\n",
    "    position = rstate[100]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedular = co_occurance_based_schedular(landmarks,visible_landmark_name,num_loi=2)\n",
    "schedular.get_node(sm,controller,res,thres)\n",
    "controller.step(\n",
    "    action=\"Teleport\",\n",
    "    position = rstate[100]\n",
    ")\n",
    "schedular.get_edge(controller)\n",
    "path = schedular.optimize()\n",
    "vis_visit_landmark(query_object,path,controller,sm,landmark_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_ithor.reset import get_min_dis\n",
    "\n",
    "min_dis = get_min_dis(query_object,controller,sm,schedular)\n",
    "print(min_dis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move To landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrtplanner = rrt.RRT(controller = controller, expand_dis=0.1,max_iter=10000,goal_sample_rate=20)\n",
    "d2w = depth2world()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Move to inital position\n",
    "'''\n",
    "controller.step(\n",
    "    action=\"Teleport\",\n",
    "    position = rstate[100]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(frames,single_pos,gt_boxes,controller,predictor,matcher,show):\n",
    "    patch = np.zeros((0,256,256,3),dtype=np.uint8)\n",
    "    map_p = []\n",
    "    sucesses = 0\n",
    "    for frame,pos,gt_box in zip(frames,single_pos,gt_boxes):\n",
    "        pred = predictor(frame)\n",
    "        pred_boxes, pred_classes, unk_only = postprocess(pred)\n",
    "        if show:\n",
    "            plot_openset(frame,pred_boxes,pred_classes,VOC_CLASS_NAMES)\n",
    "        show_patch,candidate_boxes,sucess = matcher.matching_score(frame,pred_boxes[unk_only],gt_box)\n",
    "        sucesses += torch.sum(sucess).item()\n",
    "        if len(show_patch):\n",
    "            DEPTH = controller.last_event.depth_frame\n",
    "            COLOR = controller.last_event.frame.astype(np.uint8)\n",
    "            map_points = d2w.object_coord(candidate_boxes,DEPTH,COLOR\n",
    "                                ,pos['pos'],pos['rot'])\n",
    "            patch = np.concatenate((patch,show_patch),axis=0)\n",
    "            map_p += map_points\n",
    "    return patch,map_p,sucesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_patch = np.zeros((0,256,256,3),dtype=np.uint8)\n",
    "total_mappoints = []\n",
    "angle = 60\n",
    "step = 3\n",
    "total_success = 0\n",
    "total_path_len = 0\n",
    "for p in path[1:]:\n",
    "    print(p)\n",
    "    pos = controller.last_event.metadata['agent']['position']\n",
    "    rrtplanner.set_start(pos)\n",
    "    rrtplanner.set_goal(p[0])\n",
    "    print(\"start planning\")\n",
    "    local_path = rrtplanner.planning(animation=False)\n",
    "    try:\n",
    "        smoothpath = smoothing.path_smoothing(rrtplanner,40,verbose=False)\n",
    "    except:\n",
    "        smoothpath = local_path\n",
    "    print(\"end planning\")\n",
    "    rrtplanner.plot_path(smoothpath)\n",
    "    \n",
    "    flag,path_len,frames = rrtplanner.go_with_teleport(smoothpath,maxspeed=0.2)\n",
    "    total_path_len += path_len\n",
    "    # video = ImageSequenceClip(frames, fps=10)\n",
    "    # video.write_gif('temp.gif')\n",
    "    # with open('temp.gif','rb') as file:\n",
    "    #     display(IM(file.read(),width = 300))\n",
    "    \n",
    "    pos = controller.last_event.metadata['agent']['position']\n",
    "    controller.step(\n",
    "        action=\"Teleport\",\n",
    "        position = pos, rotation = dict(x=0,y=p[1]-angle/2,z=0)\n",
    "            )\n",
    "    print(\"end move\")\n",
    "    imshow_grid = sm.plot(pos,query_object['position'])\n",
    "    plot_frames(controller.last_event,imshow_grid,landmark_config)\n",
    "    frames, single_pos,gt_boxes,gt_vis = gather(controller,[query_object['objectId']],step=step,angle=angle)\n",
    "    print('gt_vis?',gt_vis)\n",
    "    candidate_patches, candidate_map_points,sucesses = detect(frames,single_pos,gt_boxes,controller,predictor,query_matcher,show=gt_vis>0)\n",
    "    total_patch = np.concatenate((total_patch,candidate_patches),axis=0)\n",
    "    total_mappoints += candidate_map_points\n",
    "    total_success += sucesses\n",
    "    vis_panorama(frames,res=angle)\n",
    "    print(len(total_patch))\n",
    "    if len(total_patch)>30 or gt_vis:\n",
    "        break\n",
    "print(\"Sucess?\",total_success>0)\n",
    "print(\"Total Path Length\", total_path_len)\n",
    "plot_candidate(total_patch,total_mappoints,query_object_name,sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPL = (total_success>0)*min_dis/total_path_len\n",
    "print(SPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac4a03bad89aa11fa0c015257de9de10879cd3ab3f04e7a01eebec72686033e2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('ai2thor_test')",
   "name": "python388jvsc74a57bd013cd274158ba76f6a10b65be5696c6adfaef82782a391440249ecce6fcef4c3b"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}